<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" 
  xmlns:content="http://purl.org/rss/1.0/modules/content/" 
  xmlns:dc="http://purl.org/dc/elements/1.1/" 
  xmlns:atom="http://www.w3.org/2005/Atom" 
  xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" 
  xmlns:media="http://search.yahoo.com/mrss/">
  <channel>
    <title>ml on Bemore</title>
    <link>https://www.bemore.dev/tags/ml/</link>
    <description>Recent content in ml on Bemore</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>bmofinnjake08@gmail.com (bmo)</managingEditor>
    <webMaster>bmofinnjake08@gmail.com (bmo)</webMaster>
    <copyright>©2022, All Rights Reserved</copyright>
    <lastBuildDate>Tue, 05 Jul 2022 21:54:28 +0900</lastBuildDate>
    
        <atom:link href="https://www.bemore.dev/tags/ml/index.xml" rel="self" type="application/rss+xml" />
    

      
      <item>
        <title>Dropout</title>
        <link>https://www.bemore.dev/posts/ml/dropout/</link>
        <pubDate>Tue, 05 Jul 2022 21:54:28 +0900</pubDate>
        <author>bmofinnjake08@gmail.com (bmo)</author>
        <atom:modified>Tue, 05 Jul 2022 21:54:28 +0900</atom:modified>
        <guid>https://www.bemore.dev/posts/ml/dropout/</guid>
        <description>복잡한 모델이 간단한 모델보다 과적합될 가능성이 높다. 그리고 간단한 모델은 적은 수의 매개변수를 가진 모델. 복잡한 모델을 좀 더 간단하게 하는 방법으로 가중치 규제</description>
        
        <dc:creator>bmo</dc:creator>
        
        
        
        
          
            
              <category>ml</category>
            
          
            
              <category>regularization</category>
            
          
            
              <category>딥러닝</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Loss Function</title>
        <link>https://www.bemore.dev/posts/ml/lossfunction/</link>
        <pubDate>Mon, 04 Jul 2022 22:19:06 +0900</pubDate>
        <author>bmofinnjake08@gmail.com (bmo)</author>
        <atom:modified>Mon, 04 Jul 2022 22:19:06 +0900</atom:modified>
        <guid>https://www.bemore.dev/posts/ml/lossfunction/</guid>
        <description>손실 함수 신경망 학습에서 현재의 상태를 표현하는 지표(손실함수)를 기준으로 최적의 가중치 매개변수의 값을 탐색한다 SSE 오차제곱합 Sum of Squares for Error $$ E = \frac{1}{2}\displaystyle \sum_{k}(y_k - t_k)^2$$ 각</description>
        
        <dc:creator>bmo</dc:creator>
        
        
        
        
          
            
              <category>ml</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Regularization</title>
        <link>https://www.bemore.dev/posts/ml/regularization/</link>
        <pubDate>Mon, 04 Jul 2022 22:18:06 +0900</pubDate>
        <author>bmofinnjake08@gmail.com (bmo)</author>
        <atom:modified>Mon, 04 Jul 2022 22:18:06 +0900</atom:modified>
        <guid>https://www.bemore.dev/posts/ml/regularization/</guid>
        <description>가중치 규제? 복잡한 모델을 좀 더 간단한 모델로 만들어 과적합될 가능성을 낮추는 방법. 간단한 모델이란 적은 수의 매개변수를 가진 모델을 말한다. L1 regularization(=L1 norm): 모든 가중치</description>
        
        <dc:creator>bmo</dc:creator>
        
        
        
        
          
            
              <category>ml</category>
            
          
            
              <category>dls</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Improving Deep Neural Network</title>
        <link>https://www.bemore.dev/posts/ml/dls/course2_week1/</link>
        <pubDate>Mon, 04 Jul 2022 22:17:06 +0900</pubDate>
        <author>bmofinnjake08@gmail.com (bmo)</author>
        <atom:modified>Mon, 04 Jul 2022 22:17:06 +0900</atom:modified>
        <guid>https://www.bemore.dev/posts/ml/dls/course2_week1/</guid>
        <description>Dataset Dataset ➡️ train / dev / test 데이터셋 비중 이전에는 데이터셋 비중을 60% / 20% / 20% 을 이상적으로 생각했다. (10000개 정도 데이터에서는 이 비중이 이상적이지만) 1000,000 이</description>
        
        <dc:creator>bmo</dc:creator>
        
        
        
        
          
            
              <category>ml</category>
            
          
            
              <category>dls</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Activation Function</title>
        <link>https://www.bemore.dev/posts/ml/activationfunction/</link>
        <pubDate>Sat, 02 Jul 2022 22:19:06 +0900</pubDate>
        <author>bmofinnjake08@gmail.com (bmo)</author>
        <atom:modified>Sat, 02 Jul 2022 22:19:06 +0900</atom:modified>
        <guid>https://www.bemore.dev/posts/ml/activationfunction/</guid>
        <description>신경망에서 활성 함수로 쓰이는 비선형 함수들 🧨 Sigmoid $$ h(x) = \frac{1}{1 + e^{-x}} $$ 1 2 def sigmoid(x): return 1 / (1 + np.exp(-x)) 입력이 작을 떄의 출력은 0에 가깝고 입력이 커지면 출력이 1에 가까워진다.</description>
        
        <dc:creator>bmo</dc:creator>
        
        
        
        
          
            
              <category>ml</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>Hello World in Kaggle</title>
        <link>https://www.bemore.dev/posts/ml/kaggle/hello-kaggle/</link>
        <pubDate>Thu, 23 Jun 2022 22:19:06 +0900</pubDate>
        <author>bmofinnjake08@gmail.com (bmo)</author>
        <atom:modified>Thu, 23 Jun 2022 22:19:06 +0900</atom:modified>
        <guid>https://www.bemore.dev/posts/ml/kaggle/hello-kaggle/</guid>
        <description>프로그래밍을 공부하고 실습할 때 가장 먼저 해보는 print(&amp;ldquo;Hello World&amp;rdquo;) 데이터 사이언스를 공부할 때 Hello World 같은 데이터들은? Dataset MNIST Dataset Iris Project and Dataset Titanic Project and Dataset Housing Prices project and Dataset House Prices Credit Card Fraud Detection Project and Dataset</description>
        
        <dc:creator>bmo</dc:creator>
        
        
        
        
          
            
              <category>ml</category>
            
          
            
              <category>kaggle</category>
            
          
        
        
        
      </item>
      
      <item>
        <title>fastai와 파이토치가 만나 꽃피운 딥러닝 2장</title>
        <link>https://www.bemore.dev/posts/ml/fastai/ch2/</link>
        <pubDate>Wed, 08 Dec 2021 19:09:48 +0900</pubDate>
        <author>bmofinnjake08@gmail.com (bmo)</author>
        <atom:modified>Wed, 08 Dec 2021 19:09:48 +0900</atom:modified>
        <guid>https://www.bemore.dev/posts/ml/fastai/ch2/</guid>
        <description>이번 장에서는 분류 모델을 구축하면서 딥러닝의 가능성 및 제한사항을 살펴볼 수 있다. 이 곰돌이가 어떤 곰돌이인지 예측하는 모델을 다뤄봅시다 🐻 데이터 다운로드 책에</description>
        
        <dc:creator>bmo</dc:creator>
        
        
        
        
          
            
              <category>ML</category>
            
          
            
              <category>fastai</category>
            
          
        
        
          
            
              <category>ML</category>
            
          
        
        
      </item>
      

    
  </channel>
</rss>
